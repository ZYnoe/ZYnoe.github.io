[{"id":0,"href":"/ontology/docs/fetch_abstracts_documentation/","title":"Elsevier Abstract Downloader","section":"Docs","content":"Elsevier Abstract Downloader Walkthrough#\rI have implemented the Python script fetch_abstracts.py to download abstracts from Elsevier Science Direct. It is designed to handle API Rate Limits (Error 429) automatically.\nPrerequisites#\rYou need your Elsevier API Key. An Institutional Token is recommended for higher rate limits but optional.\nHow to Run#\rSet Environment Variables Open your terminal and export your keys:\nexport ELSEVIER_API_KEY=\u0026#34;your_api_key_here\u0026#34; # Optional export ELSEVIER_INST_TOKEN=\u0026#34;your_inst_token_here\u0026#34; Run the Script You can run the script directly with the CSV URL provided:\npython3 fetch_abstracts.py https://raw.githubusercontent.com/M3RG-IITD/MatSciBERT/refs/heads/main/pretraining/piis_dois.csvOr with a local file:\npython3 fetch_abstracts.py local_file.csv Features#\r429 Rate Limit Handling: Automatically waits and retries if the API limit is reached. Progress Saving: Saves abstracts.json and a checkpoint.txt every 10 items. If the script is interrupted, run it again to resume. Output: Generates abstracts.json containing the DOIs and their abstracts. Verification#\rI verified the script logic by running it without keys, confirming it correctly detects the missing configuration.\nError: ELSEVIER_API_KEY environment variable is not set.Once you set the key, it will proceed to download.\n"},{"id":1,"href":"/ontology/docs/what_is_ontology/","title":"What is Ontology","section":"Docs","content":"What is Ontology? (my understanding)#\rHow can structured concepts and relationships be distilled from unstructured data or fragmented resources to enable interoperability and retrieval?\nOntology’s value proposition is that it turns fragmented/unstructured information into interoperable and searchable structured knowledge, typically by serving as the shared semantic “schema” for data integration and querying across systems.\nCorrespondence to the papers#\rTurning unstructured data or fragmented resources into structured concepts and relationships corresponds to the ontology learning / ontology construction workflow (term extraction, term typing, taxonomy construction, relation extraction, and axiom discovery), whose goal is to transform text and similar inputs into computable concepts, hierarchies, and relations 3.\nOntologies are often described as a semantic layer that standardizes domain concepts and the relations among them, so different databases/tools/formats can “mean the same thing” even if they store data differently, which enables semantic interoperability and supports cross-source retrieval, integration, and reasoning 4 5 6.\nAn ontology is not only about “distilling structure from unstructured data”; it is a reusable semantic framework that formally captures a domain’s meaning. It uses classes, properties, and relations to provide machine-actionable definitions in formal languages such as RDF and OWL, thereby enabling automated reasoning and consistency checking 4 5.\nFor example, work in the materials domain explicitly positions an ontology as a shared, extensible model for data exchange, reuse, and integration, and as a semantic mapping layer that resolves mismatches in terminology and structure across heterogeneous databases 4.\nEngineering approach of Ontology#\rComputational materials ontology engineering approaches are usually not about a single “uniquely correct method.” Instead, an approach is chosen around the target use cases (competency questions), the form of the data sources (computational workflows/databases/literature), and interoperability requirements. Below is a practical summary of the most common engineering routes (each corresponding to typical representative works/frameworks) (Aameri et al., 2023).\nUpper-ontology alignment + modular ontology (I need to revise it because I’m still confused)#\rThe paper outlines simple, practical methods for MDS-Onto to align with upper ontologies and build modular ontologies. These approaches make the ontology flexible and compatible with broader standards. ​\nUpper Ontology Alignment#\rMDS-Onto, a domain-specific ontology, connects to top-level ontologies like BFO (Basic Formal Ontology) using mid-level bridges such as PMDco and PROV-O. The steps involve mapping core terms (e.g., \u0026ldquo;material\u0026rdquo; or \u0026ldquo;process\u0026rdquo;) to BFO\u0026rsquo;s basic categories (e.g., \u0026ldquo;continuant\u0026rdquo; for enduring things and \u0026ldquo;occurrent\u0026rdquo; for events), linking materials science concepts via PMDco for semantic sharing, and adding Schema.org plus PROV-O for web compatibility and early term conflict resolution.\nModular Ontology Design#\rMDS-Onto uses a layered setup with a top core module for shared terms and subdomain modules (e.g., X-ray or photovoltaics). Subdomains reuse top terms and add specifics (like \u0026ldquo;bandgap\u0026rdquo; for photovoltaics), keeping changes isolated; tools like FAIRmaterials help experts build and merge interoperable modules without direct dependencies, ensuring easy updates and consistency.\nSchema-first / API-first#\rSchema-first is an ontology development approach in which you first define a data schema (e.g., OPTIMADE’s standardized field definitions) and then build the ontology’s concepts and relations on top of that schema, ensuring the ontology stays aligned with existing database structures.\nThink of it like building a house: a data-first approach is like piling up materials and only then trying to design the blueprint—things can end up unstable. A schema-first approach draws the blueprint (the schema) first and then builds accordingly, so data from different databases can connect seamlessly.\nIn the paper’s development of the Materials Design Ontology (MDO), the authors follow the NeOn methodology scenario of “reusing non-ontological resources” by extracting terms from the OPTIMADE schema (a consensus data model). These terms guide the definition of concepts such as “structure,” “calculation,” and “property,” avoiding the need to start from messy raw data.\nAs a result, MDO can map data from resources like the Materials Project into RDF and support SPARQL queries (e.g., finding materials with a band gap \u0026gt; 5 eV), enabling interoperability across heterogeneous databases and aligning with the FAIR principles\nProcess-structure-property (PSP)#\rThis paragraph is intentionally left blank\nlightweight ontology#\rThis paragraph is intentionally left blank\nSemi-automated / automated ontology engineering (text mining, topic modeling, LLM-assisted).#\rLLM-supported collaborative ontology design for data and knowledge management platforms\nHIVE-4-MAT: Advancing the Ontology Infrastructure for Materials Science\n"},{"id":2,"href":"/ontology/docs/tools/","title":"Ontology packages and softwares","section":"Docs","content":"Data#\rhttps://raw.githubusercontent.com/M3RG-IITD/MatSciBERT/refs/heads/main/pretraining/piis_dois.csv\nDomain Ontologies (Ontology Datasets)#\rhttps://github.com/emmo-repo/domain-crystallography https://github.com/BIG-MAP/BattINFO\nEMMO#\rhttps://emmc.eu/emmo/\nSoftwares#\rNames URL Protégé https://protege.stanford.edu/software.php LBNLP https://lbnlp.github.io/lbnlp/ owlready2 https://pypi.org/project/owlready2/ "},{"id":3,"href":"/ontology/docs/text_extraction/","title":"101 Setup","section":"Docs","content":"Setup Instructions#\rIn this document, we will guide you through the setup process for the Ontology project.\nPapers to read#\rPDFs are available at: The Artificial Intelligence Ontology: LLM-assisted\nPrerequisites#\r%pip install --upgrade pip %pip install pandas %pip install requests %pip install bs4import requests url_nmat = \u0026#34;https://www.nature.com/articles/s41563-023-01620-2\u0026#34; response = requests.get(url_nmat)print(response) response.status_code html = response.textfrom bs4 import BeautifulSoup soup = BeautifulSoup(html, \u0026#34;html.parser\u0026#34;) abstract = soup.select_one(\u0026#34;#Abs1-content \u0026gt; p\u0026#34;)abstractabstract.get_text()def get_abstract(url): response = requests.get(\u0026#34;https://www.nature.com\u0026#34;+url) print(f\u0026#34;Reading abstracts from {url}...\u0026#34;) if response.status_code == 200: html = response.text soup = BeautifulSoup(html, \u0026#39;html.parser\u0026#39;) print(\u0026#34;Success\u0026#34;) return soup.select_one(\u0026#39;#Abs1-content \u0026gt; p\u0026#39;).get_text() else: print(f\u0026#34;Error : {response.status_code}\u0026#34;) return -1urls_nmat = [\u0026#34;/articles/s41563-023-01517-0\u0026#34;, \u0026#34;/articles/s41563-023-01572-7\u0026#34;, \u0026#34;/articles/s41563-023-01562-9\u0026#34;, \u0026#34;/articles/s41563-023-01580-7\u0026#34;, \u0026#34;/articles/s41563-023-01550-z\u0026#34;, \u0026#34;/articles/s41563-023-01585-2\u0026#34;, \u0026#34;/articles/s41563-023-01595-0\u0026#34;, \u0026#34;/articles/s41563-023-01560-x\u0026#34;, \u0026#34;/articles/s41563-023-01591-4\u0026#34;, \u0026#34;/articles/s41563-023-01598-x\u0026#34;, \u0026#34;/articles/s41563-023-01584-3\u0026#34;, \u0026#34;/articles/s41563-023-01577-2\u0026#34;]abstracts = [ get_abstract(abstract) for abstract in urls_nmat ]abstractsimport pandas as pd df = pd.DataFrame({ \u0026#34;url\u0026#34;:urls_nmat, \u0026#34;abstract\u0026#34;:abstracts }) df.to_csv(\u0026#34;extracted_abstracts.csv\u0026#34;, index=False)"},{"id":4,"href":"/ontology/docs/why/","title":"Why I Use Hugo + GitHub Pages for Materials Ontology Notes","section":"Docs","content":"Why I Use Hugo + GitHub Pages for Materials Ontology Notes#\rI chose Hugo and GitHub Pages because they are simple, fast, and good for technical notes.\nHugo lets me write in Markdown and organize my Materials Ontology notes as clear pages. It builds a static website, so it loads quickly and does not need a server or database.\nGitHub Pages is free and easy to publish. Git also keeps a history of changes, so I can update tutorials safely and track what I changed over time.\nIn the near future, I may also post other topics I learn here as part of my study notes and summaries. But don’t worry—taxonomies (tags) will help me keep everything well organized by category.\n"},{"id":5,"href":"/ontology/codes/langextract/visualization/","title":"Visualization","section":"Codes","content":"\rHighlights Legend: Classes\rA pulsed laser deposited SiO2/Ag/ZnO/Ag/TiO2 multilayer structure is studied to enhance the light trapping capability of thin-film solar cell. Structural and optical properties of structure are studied with scanning electron microscopy, x-ray diffraction, photoluminescence and UV–visible spectroscopy. Proposed geometry improves the extinction spectra and quenches photoluminescence in comparison to TiO2/Ag and SiO2/Ag/ZnO geometry. Finite-difference time-domain (FDTD) simulations indicate a promising effect of the proposed geometries on thin-film solar cells. Twofold enhancement in total quantum efficiency of an optimized multilayer plasmonic graded-index thin-film solar cell is observed in comparison to the pristine solar cell. Results suggest a more concerted study of multilayer plasmonic nanostructures with graded-index anti-reflection coatings to improve the performance of thin-film photovoltaic devices.\r▶️ Play\r⏮ Previous\r⏭ Next\rEntity 1/4 |\rPos [0-302]\r"}]