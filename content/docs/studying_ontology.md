---
title: "What is ontology and semantic memory?"
weight: 1
# bookFlatSection: false
# bookToc: true
# draft: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: false
# bookSearchExclude: false
# bookHref: ''
# bookIcon: ''
date: "2026-01-27T15:00:56.273Z"
draft: false
tags:
- Ontology Tutorial
categories:
- technical
---


## Is my `.jsonl` dataset a semantic memory dataset?

**Short answer:**  
Yes â€” your dataset *can* function as a semantic memory dataset, *but it depends on how you define it and how you plan to use it.*

### Clarification

- A **semantic memory dataset** in AI/knowledge systems typically means **structured knowledge that captures meanings, concepts, and relationships**, not just raw text.
- In your case, the `.jsonl` contains **materials properties and characteristics extracted automatically** from 100k peer-reviewed abstracts. That is **structured, factual knowledge about domain concepts**, which is *exactly the kind of data that could serve as semantic memory*.

So your JSONL has:

âœ”ï¸ Entities (materials, properties)  
âœ”ï¸ Attributes (values, conditions, evidence)  
âœ”ï¸ Machine-readable structure

That is *semantic knowledge*, even if itâ€™s not yet a fully conceived ontology with a schema, classes, axioms, logic constraints, etc.

ğŸ“Œ **Conclusion:**  
Your data qualifies as a **semantic knowledge dataset** (like â€œmemoryâ€), but **not yet a full ontology** in the strict sense.

---

## Does what you are doing fit the ontology construction methodology described in the article?

**Short answer:**  
Partially â€” your current practice overlaps with thematic parts of the methodology, but it is not yet the full methodology as described.

---

### What You *Are* Doing

Your current pipeline:

1. **Text mining** â†’ extract facts from abstracts  
2. Output â†’ `JSONL` with structured fields like:
   - `material`
   - `property`
   - `value`
   - `unit`
   - `condition`
   - `evidence`

This matches **instance extraction** from text â€” essentially:

> â€œConcrete facts or triples about real things in the worldâ€  

This is exactly what **instance data** in a semantic knowledge system is supposed to be. Itâ€™s the *populated facts* that an ontology can later operate over.

So:

âœ… You are building **domain instance data**  
âœ… You are extracting structured knowledge from unstructured text  
âœ… It *can* support ontology validation and usage  

Butâ€¦

---

### What the Ontology Methodology Includes (Beyond Instance Extraction)

According to the articleâ€™s methodology, an ontology development process includes a **schema layer** and an **instance layer**:

1. **Scenarios & Glossary**  
2. **Competency Questions**  
3. **Modelet Development (schema / classes / properties)**  
4. **Test Case Generation (e.g., SPARQL)**  
5. **Model Refinement**  
6. **Documentation**  
7. **Feedback and iteration**

Your current work focuses on **instance data**, but the methodology emphasizes structuring and refining the **schema first**, *before* you generate and use instance data.

So right now you have:

ğŸ”¹ **Instance facts only**  
âœ–ï¸ Not yet a structured domain schema or ontology backbone  
âœ–ï¸ No competency questions defined formally  
âœ–ï¸ No test cases derived from ICQs  
âœ–ï¸ No iterative refinement loop between schema â†” data

---

## So the answer is

### â“ Is your JSONL a semantic memory dataset?

â¡ï¸ **Yes, in terms of extracted structured data representing domain knowledge.**

### â“ Is what you are doing the full ontology methodology from the article?

â¡ï¸ **Not yet â€” it covers important parts, but you have done mostly instance extraction, not full ontology engineering.**

---

## How the Two Can Fit Together

Hereâ€™s one way to map your workflow into the ontology method:

| Your Current Step                                   | Article Method Step              |
|-----------------------------------------------------|----------------------------------|
| Extract properties from abstracts â†’ JSONL           | **Instance layer**               |
| (Future) Define schemas for materials, properties    | **Modelet / Ontology schema**    |
| Generate competency questions based on domain needs | **ICQs**                         |
| Use ICQs + schema to design tests                   | **Test Case Generation**         |
| Validate your extracted facts against schema & tests | **Refinement**                   |
| Document ontology and iteration results             | **Documentation + Feedback**     |

So your data is **a great foundation** â€” especially for:

- **Validating ontology**
- **Providing empirical evidence**
- **Feeding test case results**
- **Driving iterative improvement**

---

## Bottom Line

ğŸ“Œ **Your JSONL dataset is semantic knowledge (semantic memory)**  
ğŸ“Œ **Your work is *part* of ontology building, specifically instance extraction**  
ğŸ“Œ **To fully match the methodology, you should add schema, competency questions, test cases, documentation, and iterative feedback**
